# ðŸ¤– KareAI MCP Chatbot

A smart chatbot that connects to an MCP (Model Context Protocol) server and fetches real-time data in a human-friendly way â€” powered by OpenRouter LLMs and a Streamlit interface.

---

## ðŸ” Project Overview

This chatbot simulates an intelligent assistant that:

- ðŸ”— Connects to an MCP server (e.g., Firecrawl or JSONPlaceholder)
- ðŸ“¥ Fetches structured data from the MCP API
- ðŸ§  Summarizes and explains the response using an LLM
- ðŸ§¾ Displays results in plain English via a chatbot interface

---

## ðŸ§° Tech Stack

| Layer     | Tech Used                         |
|-----------|-----------------------------------|
| ðŸ’¬ LLM     | OpenRouter (Free GPT/Claude models) |
| ðŸ§  MCP API | Firecrawl or JSONPlaceholder      |
| ðŸ–¥ Frontend| Streamlit                         |
| ðŸ” Backend | Python (requests, dotenv, etc.)   |

---

## âš™ï¸ Folder Structure

kareai_chatbot/
â”‚
â”œâ”€â”€ backend/
â”‚ â”œâ”€â”€ main.py # Flask or API layer (optional)
â”‚ â”œâ”€â”€ mcp_client.py # Connects to MCP server
â”‚ â”œâ”€â”€ llm_processor.py # Summarizes data using OpenRouter
â”‚ â””â”€â”€ requirements.txt # Dependencies
â”‚
â”œâ”€â”€ frontend/
â”‚ â””â”€â”€ streamlit_app.py # Chatbot UI in Streamlit
â”‚
â”œâ”€â”€ MiniMax-MCP-JS/ # MCP server client (optional, for testing)
â”œâ”€â”€ .env # ðŸ”’ Secrets (excluded from Git)
â”œâ”€â”€ .env.example # âœ… Safe reference
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md

---

## ðŸš€ How to Run Locally

 **1. Clone the repo**
git clone https://github.com/Kusuma-GM/kareai_chatbot.git
cd kareai_chatbot

**2. Set up virtual environment**
python -m venv venv
.\venv\Scripts\activate      # On Windows
pip install -r backend/requirements.txt

**3. Set up .env**
Create a .env file in the root:
env
OPENAI_API_KEY=sk-or-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
MCP_BASE_URL=https://jsonplaceholder.typicode.com/posts
ðŸ” Never commit this file! Use .env.example for safe sharing.

**4. Start the chatbot**

streamlit run frontend/streamlit_app.py
ðŸ’¡ How It Works
User enters a natural language question.

App sends a GET request to the MCP server.

Raw response is sent to the LLM for summarization.

A clean, human-readable answer is displayed.



**Submission Checklist (Kimmchi)**
 Working chatbot interface âœ…
echo "* text=auto" > .gitattributes

 Connected to MCP server (e.g. Firecrawl or JSONPlaceholder) âœ…

 Summarizes response using LLM âœ…

 All code uploaded to GitHub âœ…

 

**ðŸ“¬ Contact**
For any help or feedback, feel free to reach out at:
ðŸ“§ gmkusuma619@gmail.com


